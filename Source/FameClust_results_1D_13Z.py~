
#Script which follows Fortran run, and defines 1D probabilities

#Execution: time python FameClust_results_1D_13Z.py InputFameClustNEW_UBVRI_Z01900_M400 1 10 all

import numpy as np
import numexpr as ne
import scipy
import os
import os.path
import math
import time
import random
from random import gauss
import pylab
from pylab import *
import sys
import Lecture_module  # (Module located in /home/philippe/Desktop/Discrete_models_comparaison_jtao)
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.mlab as mlab
from matplotlib.colors import LogNorm
import mpl_toolkits.axisartist as axisartist

params = {'axes.labelsize': 9,
          'axes.linewidth': 0.5,
          'text.fontsize': 9,
          'xtick.labelsize': 6,   #Before 8
          'ytick.labelsize': 6,   #Before 8
	  'xtick.major.pad': 4,	  #Before 8
	  'ytick.major.pad': 4,	  #Before 8
          'text.usetex': False,
          'xtick.major.size': 3.5,
          'ytick.major.size': 3.5,
          'xtick.minor.size': 2,
          'ytick.minor.size': 2,
#          'ps.usedistiller': 'xpdf',
          'ps.distiller.res': 6000,
#          'ps.fonttype': 42,
#          'pdf.compression': 0,
          'pdf.fonttype': 42
          }
plt.rcParams.update(params)


#------------------------------------------------------------------------------------------------

def Filtering_of_very_low_probable_extinctions(logt_box,logm_box,Ebv_box,Z_box,weights):
 #Fortran program outputs age/mass nodes with different possibilities for the extinction. Some are very low probable.
 #In this function, for each age/mass node, we filter the solutions for which the probability is less than 
 #28% the one of the most probable extinction.
 for zz in range(0,13):
  zz = 2+2*zz
  for aa in range(1,72):
   for mm in range(1,62): 
    age, mass, Z, age_indice, mass_indice, Z_indice = Lecture_module.age_mass_Z_December2011(aa,mm,zz) 
    age_indice_int = int(age_indice)
    mass_indice_int= int(mass_indice)
    mask = ne.evaluate('(logt_box==age_indice_int) & (logm_box==mass_indice_int) & (Z_box==zz)')
    index=np.where(mask)
    if len(index[0])>0:
     max_proba = weights[index].max()
     for kk in range(0,len(index[0])):
      if weights[index[0][kk]]<0.28*max_proba: weights[index[0][kk]] = 0.
      #if age_indice_int==980: print weights[index[0][kk]],0.28*max_proba
 mask_weight = ne.evaluate('weights>0')
 #print len(mask_weight)
 #filtered_index = np.where(mask_weight)
 #print filtered_index[0][:50]
 return logt_box[mask_weight], logm_box[mask_weight], Ebv_box[mask_weight], Z_box[mask_weight], weights[mask_weight]



def Mass_rounding(Age_grid,Mass_grid):
 #The masses of the cluster models in the grids are not exactly the ones desired (small differences in the building)
 #Here I need to have exact masses, so I round them.
 #print Mass_grid[1000900:1001000]
 Age_grid_rounded = np.zeros((4331000,), dtype=np.int)
 Mass_grid_rounded = np.zeros((4331000,), dtype=np.int)
 for aa in range(1,72):
  for mm in range(1,62):
   age, mass, Z, age_indice, mass_indice, Z_indice = Lecture_module.age_mass_Z_December2011(aa,mm,zz)
   Mass_grid_rounded[0+(mm-1)*1000+(aa-1)*61000:1000+(mm-1)*1000+(aa-1)*61000] = int(mass_indice) #log10(mass)
  Age_grid_rounded[0+(aa-1)*61000:61000+(aa-1)*61000] = int(age_indice)
 return Age_grid_rounded,Mass_grid_rounded


def Error_bars(age_centers,age_histo,age_1D):
 #Age error bar (34% left and 34% right)
 hist_1D_all = 0.				#to have the integral of the histogram (only sum of bars)
 for bb in range(0,len(age_histo)):		
  hist_1D_all = hist_1D_all + age_histo[bb]		
 sum34pc_left = 0.				
 for bb in range(0,len(age_centers)):		
  sum34pc_left = sum34pc_left + age_histo[bb]
  if sum34pc_left >= hist_1D_all*0.1585: break
 age_1D_left_value = min(age_centers[bb],age_1D) #+ 0.05
 sigma_left_age = abs(age_1D - age_1D_left_value)
 sum34pc_right = 0.					#to have the integral of the histogram (only sum of bars)
 for bb in range(0,len(age_centers)):		
  sum34pc_right = sum34pc_right + age_histo[bb]
  if sum34pc_right >= hist_1D_all*0.8415: break
 age_1D_right_value = max(age_centers[bb],age_1D) #+ 0.05
 sigma_right_age = abs(age_1D - age_1D_right_value)
 return age_1D_left_value,age_1D_right_value #,sum34pc_left,sum34pc_right

#------------------------------------------------------------------------------------------------

Cores_number = ne.detect_number_of_cores()
ne.set_num_threads(Cores_number)
#print Cores_number
#raw_input()

# -------------------------
# Loading of the input file (should be the same as for Fortran run)
# -------------------------
print
print 80*'-'
print
print 50*'-'
print 'Loading of InputFile'
print 50*'-'
print

InputFile_Name = sys.argv[1] # The name of input file is given during execution of the script
number_begin = int(sys.argv[2])
number_end = int(sys.argv[3])
Z_selected = sys.argv[4]

Z_indice_selected = Z_selected
print Z_indice_selected
if Z_selected != 'all':
 Z,zz = Lecture_module.Zindex_to_Z_and_zz(Z_indice_selected)
#if Z_selected == 'all':

InputFile = open('/home/philippe/Desktop/Discrete_models_comparaison_jtao/SC_Parameters_20/'+InputFile_Name).readlines()
my_list = []
for line in InputFile:
    item = str.split(line)
    if item[0][0] != '#':
     my_list.append(item[0])

number_filters = int(my_list[0])
print 'Number of filters selected:                 ', number_filters
filters_selected_index = np.arange(number_filters) 	#integer array containing the indexes of the selected filters 
for ii in range(0,number_filters):
 filters_selected_index[ii] = int(my_list[ii+1])
print 'Indexes of filters selected:               ', filters_selected_index
Distance_modulus_host_galaxy = int(my_list[number_filters+1])
print 'Distance modulus of the host galaxy:        ', Distance_modulus_host_galaxy
app_or_abs = int(my_list[number_filters+2])
print 'Apparent mags [1], Absolute mags [2]:       ', app_or_abs
file_observed_clusters = my_list[number_filters+3]
print 'Input file of the observed clusters:        '
print '    ',file_observed_clusters
number_cluster_observed = int(my_list[number_filters+4])
print 'Number of observed clusters:                ',  number_cluster_observed	#[obsolete]
choice_extinction = int(my_list[number_filters+5])
print 'Cluster(s) extincted [1], not extincted [2]:', choice_extinction
choice_extinction_law = int(my_list[number_filters+6])
print 'Extinction law of MW [1], of LMC [2]:       ', choice_extinction_law
path_file_out_cluster = my_list[number_filters+7]
print 'Path of output files for derived parameters:' 
print '    ',path_file_out_cluster
print
print 50*'-'
print 'InputFile loaded'
print 50*'-'
print
#raw_input()


# -----------------------------------------------------------------------------------------
#Loading of the observations
# -----------------------------------------------------------------------------------------
print
print 50*'-'
print 'Loading of the observation'
print 50*'-'
print
#file: file_observed_clusters
#print path_file_out_cluster+file_observed_clusters
data_input = np.genfromtxt(path_file_out_cluster+file_observed_clusters, comments='#')
M1_input = data_input[:,filters_selected_index+4]
print 'M1: ', M1_input
#print 'M1[0:number_filters]: ', M1[0:number_filters]
del data_input
print 50*'-'
print 'Observation loaded'
print 50*'-'
print
#raw_input()


# -----------------------------------------------------------------------------------------
#Loading of the A_lambda (extinction parameters) for the filters selected in the input file
# -----------------------------------------------------------------------------------------
print
print 50*'-'
print 'Loading of the A_lambda (extinction parameters)'
print 50*'-'
print
# lambda, lambda_f_MW, lambda_f_LMC, index of filter [1-->52]
filters_A_lambda = np.genfromtxt('Filters_information.dat',comments='#')
if choice_extinction_law == 1:	#MW
 A_lambda_filters_selected = filters_A_lambda[filters_selected_index-1,1]
 Rv = 3.1
if choice_extinction_law == 2:	#LMC
 A_lambda_filters_selected = filters_A_lambda[filters_selected_index-1,2]
 Rv = 3.4
print A_lambda_filters_selected
print
print 50*'-'
print 'A_lambda loaded'
print 50*'-'
print
del filters_A_lambda
#raw_input()


# ----------------------------------------------
# Loading of the grid of models (from .npy file)
# ----------------------------------------------
#Z_indice = 'n00' #Here, make a simple test to see if there is a file for the metallicity Z=... (loop on 13 Z)
#zz=24
if Z_selected != 'all':
 Z_indice = Z_selected
 Z,zz = Lecture_module.Zindex_to_Z_and_zz(Z_indice)
 #Loading of the grid(s) needed 
 #grid = np.load('/home/philippe/Desktop/Discrete_models_comparaison_jtao/Transforming_grid_in_npy_files/Grid_HRS_Z{0}_ExpFactor6_Kroupa.npy'.format(Z_indice))
 grid = np.load('/home/philippe/Desktop/Discrete_models_comparaison_jtao/Transforming_grid_in_npy_files/Grid_HRS_Z{0}_ExpFactor6_Weidner_corrected.npy'.format(Z_indice))
 Age_grid = grid[:,0][np.newaxis].T
 Mass_grid = grid[:,1][np.newaxis].T

 #Rounding of the masses of models (for selection)
 #print Mass_grid[2000900:2001000]
 Age_grid_rounded,Mass_grid_rounded = Mass_rounding(Age_grid,Mass_grid)
 #print Mass_grid_rounded[2000900:2001000]
 #mask = ne.evaluate('(Age_grid_rounded==680) & (Mass_grid_rounded==315)')
 #index = np.where(mask)

if Z_selected == 'all':
 Z_grid_rounded = np.zeros((13*4331000,), dtype=np.int)
 #Z_indice = 'all'
 #for jj in range(0,13):	#Loop on the 3 output metallicities
 for jj in range(0,1):	#Loop on the 3 output metallicities
  zz = 2+2*jj
  Z,Z_indice = Lecture_module.zz_to_Z_and_Zindex(zz)
  Z_grid_rounded[0+jj*4331000:4331000+jj*4331000] = zz


  #Loading of the grid(s) needed 
  if jj==0: 
   #grid = np.load('/home/philippe/Desktop/Discrete_models_comparaison_jtao/Transforming_grid_in_npy_files/Grid_HRS_Z{0}_ExpFactor6_Kroupa.npy'.format(Z_indice))
   grid = np.load('/home/philippe/Desktop/Discrete_models_comparaison_jtao/Transforming_grid_in_npy_files/Grid_HRS_Z{0}_ExpFactor6_Weidner_corrected.npy'.format(Z_indice))
   Age_grid = grid[:,0][np.newaxis].T
   Mass_grid = grid[:,1][np.newaxis].T
  if jj>0:
   #grid_add = np.load('/home/philippe/Desktop/Discrete_models_comparaison_jtao/Transforming_grid_in_npy_files/Grid_HRS_Z{0}_ExpFactor6_Kroupa.npy'.format(Z_indice))
   grid_add = np.load('/home/philippe/Desktop/Discrete_models_comparaison_jtao/Transforming_grid_in_npy_files/Grid_HRS_Z{0}_ExpFactor6_Weidner_corrected.npy'.format(Z_indice))
   grid = np.concatenate((grid,grid_add), axis=0)


 #Rounding of the masses of models (for selection)
 #print Mass_grid[2000900:2001000]
 Age_grid_rounded,Mass_grid_rounded = Mass_rounding(Age_grid,Mass_grid)
 Age_grid_rounded_bis = Age_grid_rounded
 Mass_grid_rounded_bis = Mass_grid_rounded
 #for jj in range(0,12):
 # Age_grid_rounded = np.concatenate((Age_grid_rounded,Age_grid_rounded_bis), axis=1)
 # Mass_grid_rounded = np.concatenate((Mass_grid_rounded,Mass_grid_rounded_bis), axis=1)



sigma_magnitude = 0.05
sigma_magnitude_square_inverse = 1./sigma_magnitude**2
solution = np.zeros((number_end,4))


#Loop on all observed clusters
for ii in range(number_begin,number_end+1):
 M1 = M1_input[ii-1]
 print M1

 #First task: for ALL metallicities, filter the solutions with very low probable extinctions, and put all the nodes in one array

 if Z_selected != 'all':
  fname = path_file_out_cluster+'Cluster_{0}_node_Z{1}_V103.dat'.format(str(ii),Z_indice)
  if os.path.isfile(fname) == True:
   data_models = np.genfromtxt(fname,comments='#')
   logt_box=data_models[:,0]#/100.
   logm_box=data_models[:,1]#/100.
   Ebv_box=(data_models[:,2]-1.)/50.
   Z_box = zz
   weights=data_models[:,3]
   index_max_age_3D = np.argmax(weights)
   logt_box_filtered, logm_box_filtered, Ebv_box_filtered, Z_box_filtered, weights_filtered = Filtering_of_very_low_probable_extinctions(logt_box,logm_box,Ebv_box,Z_box,weights)


 if Z_selected == 'all':
  flag_first = 1
 # for jj in range(0,13):	#Loop on the 3 output metallicities
  for jj in range(0,1):	#Loop on the 3 output metallicities
   zz = 2+2*jj
   Z,Z_indice = Lecture_module.zz_to_Z_and_Zindex(zz)
   fname = path_file_out_cluster+'Cluster_{0}_node_Z{1}_V103.dat'.format(str(ii),Z_indice)
   if os.path.isfile(fname) == True:
    if jj==0:
     data_models = np.genfromtxt(path_file_out_cluster+'Cluster_{0}_node_Z{1}_V103.dat'.format(str(ii),Z_indice),comments='#')
     logt_box=data_models[:,0]#/100.
     logm_box=data_models[:,1]#/100.
     Ebv_box=(data_models[:,2]-1.)/50.
     Z_box = np.zeros((len(logt_box),), dtype=np.int)
     Z_box[:] = 2+jj*2
     weights=data_models[:,3]
     flag_first = 0
     print "HHHHHHHHHHHHHHHHHHHHHHHHHOOOOOOOOOOOOOOOOOOO"
    
    if jj>0:
     if flag_first==1:
      data_models = np.genfromtxt(path_file_out_cluster+'Cluster_{0}_node_Z{1}_V103.dat'.format(str(ii),Z_indice),comments='#')
      logt_box=data_models[:,0]#/100.
      logm_box=data_models[:,1]#/100.
      Ebv_box=(data_models[:,2]-1.)/50.
      Z_box = np.zeros((len(logt_box),), dtype=np.int)
      Z_box[:] = 2+jj*2
      weights=data_models[:,3]
      flag_first = 0

     if flag_first==0:
      data_models = np.genfromtxt(path_file_out_cluster+'Cluster_{0}_node_Z{1}_V103.dat'.format(str(ii),Z_indice),comments='#')
      logt_box=np.concatenate((logt_box,data_models[:,0])         ,axis=0)  #data_models[:,0]#/100.
      logm_box=np.concatenate((logm_box,data_models[:,1])         ,axis=0)  #data_models[:,1]#/100.
      Ebv_box= np.concatenate((Ebv_box ,(data_models[:,2]-1.)/50.),axis=0)  #(data_models[:,2]-1.)/50.
      Z_box_new = np.zeros((len(data_models[:,0]),), dtype=np.int)
      Z_box_new[:] = 2+jj*2
      Z_box  = np.concatenate((Z_box,Z_box_new),axis=0)
      weights= np.concatenate((weights ,data_models[:,3])         ,axis=0)  #data_models[:,3]
  
  
  #Let's filter the very low probable solutions, the ones for which the probability is less than 0.1% of the most probable solution
  weight_max = weights.max()
  mask = ne.evaluate('weights>weight_max*0.001')
  logt_box_filtered = logt_box[mask]
  logm_box_filtered = logm_box[mask]
  Ebv_box_filtered = Ebv_box[mask]
  Z_box_filtered = Z_box[mask]
  weights_filtered = weights[mask]
  index_max_age_3D = np.argmax(weights_filtered)
  print len(logt_box), len(logt_box_filtered)
 print 'hello'

 #sys.exit()
 #raw_input()



 #Second task: open all the node files, and put the models in a huge array containing the age, mass, extinction, Z, filters of each model.
 #Ideally, i should open the grids before, and then take the models of the desired node.
 models_selected = np.zeros((len(logt_box_filtered)*1000,4+number_filters+1)) #Array creation
 M0 =              np.zeros((len(logt_box_filtered)*1000,number_filters)) #Array creation
 M0_prime =        np.zeros((len(logt_box_filtered)*1000,number_filters)) #Array creation
 for kk in range(0,len(logt_box_filtered)): #len(logt_box_filtered)):
  #print kk
  models_selected[0+kk*1000:1000+kk*1000,0] = logt_box_filtered[kk]
  models_selected[0+kk*1000:1000+kk*1000,1] = logm_box_filtered[kk]
  models_selected[0+kk*1000:1000+kk*1000,2] = Ebv_box_filtered[kk]
  #models_selected[0+kk*1000:1000+kk*1000,3] = Z_box_filtered[kk] 
  age_indice = str(logt_box_filtered[kk]) #int(round(logt_box_filtered[kk]*100))#int(round(6.8*100))# logt_box_filtered[kk]
  mass_indice = str(logm_box_filtered[kk]) #int(round(logm_box_filtered[kk]*100)) #int(round(3.15*100)) #logm_box_filtered[kk]
  zz = Z_box_filtered[kk]
  aa,mm,zz_bidon = Lecture_module.indices_to_aa_mm_zz(age_indice, mass_indice, Z_indice)
  jj = (zz-2)/2 
  models_selected[0+kk*1000:1000+kk*1000,4:4+number_filters] = grid[0+jj*4331000+(aa-1)*61000+(mm-1)*1000:1000+jj*4331000+(aa-1)*61000+(mm-1)*1000, filters_selected_index[0]+1:filters_selected_index[-1]+2]
  M0[0+kk*1000:1000+kk*1000,0:number_filters] = grid[0+jj*4331000+(aa-1)*61000+(mm-1)*1000:1000+jj*4331000+(aa-1)*61000+(mm-1)*1000, filters_selected_index[0]+1:filters_selected_index[-1]+2]
  Z, Z_indice = Lecture_module.zz_to_Z_and_Zindex(zz)
  models_selected[0+kk*1000:1000+kk*1000,3] = 12-jj  #To put the metallic to left in histogram
  #if jj<2: print jj

 print len(models_selected[:,0])
 print 'hello 2'



 #Third task: redden all the models with the extinction associated
 for ff in range(0,number_filters):
  M0_prime[:,ff] = M0[:,ff] + A_lambda_filters_selected[ff] * Rv*models_selected[:,2]



 #Fourth task: compute the gaussian weight for all models, based on the distance to the observation. 
 #So i need to compute the n-dimensional distance of each point to the observation.
 d_direct_square = ne.evaluate("(M1-M0_prime)*(M1-M0_prime)").sum(axis=1)
 #gaussian_weights = np.exp(-0.5*(d_direct_square[:]*sigma_magnitude_square_inverse))
 models_selected[:,4+number_filters] = np.exp(-0.5*(d_direct_square[:]*sigma_magnitude_square_inverse))


 #Lasts adjustments
 models_selected[:,0:2] = models_selected[:,0:2]/100.
 models_selected[:,4:4+number_filters] = M0_prime[:]

 np.save('/home/philippe/Desktop/bidon.npy',models_selected)


 #Fifth task: the 1D histograms
 # ------------------------------------
 # Building the probabilitieS 1D		#I could also build the 3D!!!
 # ------------------------------------

 #pars_age_1Z_vs_3Z = matplotlib.figure.SubplotParams(left=0.015, bottom=0.15, right=0.985, top=0.92, wspace=0., hspace=0.4)
 #fig    = plt.figure(1,figsize=(260/25.4,80/25.4),subplotpars=pars_age_1Z_vs_3Z)

 pars_age_1Z_vs_3Z = matplotlib.figure.SubplotParams(left=0.05, bottom=0.17, right=0.985, top=0.925, wspace=0.05, hspace=0.4)
 fig    = plt.figure(1,figsize=(350/25.4,105/25.4),subplotpars=pars_age_1Z_vs_3Z)

 #AGE--------------------------------------------------------------------------------------------------
 ax_age = fig.add_subplot(141)	
 age_histo, age_edges = np.histogram(models_selected[:,0], bins=71, range=[6.575,10.125], normed=True, weights=models_selected[:,4+number_filters], density=None)
 index_max_age = np.argmax(age_histo)
 age_centers = (age_edges[:-1]+age_edges[1:])/2
 age_1D = age_centers[index_max_age] 	
 width_age = (age_edges[1]-age_edges[0])
 ax_age.bar(age_centers, age_histo, align = 'center', width = width_age, color=(0./256.,126./256.,253./256.))
 #ax_age.set_xlim(6.575,10.125)
 labels = [item.get_text() for item in ax_age.get_yticklabels()] 
 labels[:] = ''
 ax_age.set_yticklabels(labels)
 #Age error bar (34% left and 34% right)
 age_1D_left_value,age_1D_right_value = Error_bars(age_centers,age_histo,age_1D)
 sigma_left_age = abs(age_1D - age_1D_left_value)
 sigma_right_age = abs(age_1D - age_1D_right_value)
 l_age_left = ax_age.axvline(x=age_1D_left_value,linewidth=3, ls='--', dashes=(10,10), color='r')
 l_age = ax_age.axvline(x=age_1D,linewidth=3, color='r')
 l_age_right = ax_age.axvline(x=age_1D_right_value,linewidth=3, ls='--', dashes=(10,10), color='r')
 ax_age.set_xlim(6.5,10.2)
 ax_age.set_xticks([7, 8, 9, 10])
 ax_age.set_xlabel(r'log($t/yr$)', labelpad=0,fontsize=24)
 ax_age.tick_params(axis='both', which='major', labelsize=20)
 #xlabel(r'log($t$/yr)')
 ax_age.set_ylabel(r'Probability density',fontsize=22)
 #AGE--------------------------------------------------------------------------------------------------



 #MASS-------------------------------------------------------------------------------------------------
 ax_mass = fig.add_subplot(142) #(142, sharey=ax_age)
 mass_histo, mass_edges = np.histogram(models_selected[:,1], bins=81, range=[1.975,6.025], normed=True, weights=models_selected[:,4+number_filters], density=None)
 index_max_mass = np.argmax(mass_histo)
 mass_centers = (mass_edges[:-1]+mass_edges[1:])/2
 mass_1D = mass_centers[index_max_mass] 	
 width_mass = (mass_edges[1]-mass_edges[0])
 ax_mass.bar(mass_centers, mass_histo, align = 'center', width = width_mass, color=(0./256.,126./256.,253./256.))
 ax_mass.set_xlim(1.975,5.025)
 ax_mass.set_xticks([2, 3, 4, 5])
 ax_mass.set_xlabel(r'log($m$/${\rm M}_{\odot}$)', labelpad=0,fontsize=24)
 ax_mass.tick_params(axis='both', which='major', labelsize=20)
 labels = [item.get_text() for item in ax_mass.get_yticklabels()] 
 labels[:] = ''
 ax_mass.set_yticklabels(labels)
 #mass error bar (34% left and 34% right)
 mass_1D_left_value,mass_1D_right_value = Error_bars(mass_centers,mass_histo,mass_1D)
 sigma_left_mass = abs(mass_1D - mass_1D_left_value)
 sigma_right_mass = abs(mass_1D - mass_1D_right_value)
 l_mass_left = ax_mass.axvline(x=mass_1D_left_value,linewidth=3, ls='--', dashes=(10,10), color='r')
 l_mass = ax_mass.axvline(x=mass_1D,linewidth=3, color='r')
 l_mass_right = ax_mass.axvline(x=mass_1D_right_value,linewidth=3, ls='--', dashes=(10,10), color='r') 
 #xlabel(r'log($M$/${\rm M}_{\odot}$)')
 #MASS-------------------------------------------------------------------------------------------------



 #E(B-V)-----------------------------------------------------------------------------------------------
 ax_Ebv = fig.add_subplot(143) #(143, sharey=ax_age)
 Ebv_histo, Ebv_edges = np.histogram(models_selected[:,2], bins=101, range=[-0.01,2.01], normed=True, weights=models_selected[:,4+number_filters], density=None)
 index_max_Ebv = np.argmax(Ebv_histo)
 Ebv_centers = (Ebv_edges[:-1]+Ebv_edges[1:])/2
 Ebv_1D = Ebv_centers[index_max_Ebv] 	
 width_Ebv = (Ebv_edges[1]-Ebv_edges[0])
 ax_Ebv.bar(Ebv_centers, Ebv_histo, align = 'center', width = width_Ebv, color=(0./256.,126./256.,253./256.))
 ax_Ebv.set_xlim(-0.01,1.01)
 ax_Ebv.set_xticks([0.2, 0.4, 0.6, 0.8])
 ax_Ebv.set_xlabel(r'$E(B-V)$', labelpad=0,fontsize=24)
 ax_Ebv.tick_params(axis='both', which='major', labelsize=20)
 labels = [item.get_text() for item in ax_Ebv.get_yticklabels()] 
 labels[:] = ''
 ax_Ebv.set_yticklabels(labels)
 #Ebv error bar (34% left and 34% right)
 Ebv_1D_left_value,Ebv_1D_right_value = Error_bars(Ebv_centers,Ebv_histo,Ebv_1D)
 sigma_left_Ebv = abs(Ebv_1D - Ebv_1D_left_value)
 sigma_right_Ebv = abs(Ebv_1D - Ebv_1D_right_value)
 l_Ebv_left = ax_Ebv.axvline(x=Ebv_1D_left_value,linewidth=3, ls='--', dashes=(10,10), color='r')
 l_Ebv = ax_Ebv.axvline(x=Ebv_1D,linewidth=3, color='r')
 l_Ebv_right = ax_Ebv.axvline(x=Ebv_1D_right_value,linewidth=3, ls='--', dashes=(10,10), color='r')
 #xlabel(r'$E(B-V)$')
 #E(B-V)-----------------------------------------------------------------------------------------------


 #Z----------------------------------------------------------------------------------------------------
 ax_Z = fig.add_subplot(144) #(144, sharey=ax_age)
 Z_histo, Z_edges = np.histogram(models_selected[:,3], bins=13, range=[-0.5,12.5], normed=True, weights=models_selected[:,4+number_filters], density=None)
 index_max_Z = np.argmax(Z_histo)
 Z_centers = (Z_edges[:-1]+Z_edges[1:])/2
 Z_1D = Z_centers[index_max_Z] 	
 width_Z = (Z_edges[1]-Z_edges[0])
 ax_Z.bar(Z_centers, Z_histo, align = 'center', width = width_Z, color=(0./256.,126./256.,253./256.))
 ax_Z.set_xlim(-0.5,12.5)
 labels = [item.get_text() for item in ax_Z.get_xticklabels()]
 labels[1] = '0.03'
 labels[3] = '0.005'
 labels[5] = '0.0008'
 ax_Z.set_xticklabels(labels)
 ax_Z.set_xlabel(r'$Z$', labelpad=2,fontsize=24)
 ax_Z.tick_params(axis='both', which='major', labelsize=20)
 #ax_Z.set_ylabel(r'N')
 labels = [item.get_text() for item in ax_Z.get_yticklabels()] 
 labels[:] = ''
 ax_Z.set_yticklabels(labels)
 #Z error bar (34% left and 34% right)
 Z_1D_left_value,Z_1D_right_value = Error_bars(Z_centers,Z_histo,Z_1D)
 sigma_left_Z = abs(Z_1D - Z_1D_left_value)
 sigma_right_Z = abs(Z_1D - Z_1D_right_value)
 l_Z_left = ax_Z.axvline(x=Z_1D_left_value,linewidth=3, ls='--', dashes=(10,10), color='r')
 l_Z = ax_Z.axvline(x=Z_1D,linewidth=3, color='r')
 l_Z_right = ax_Z.axvline(x=Z_1D_right_value,linewidth=3, ls='--', dashes=(10,10), color='r')
 #Z----------------------------------------------------------------------------------------------------






 plt.show()

 solution[ii-1,0:4] = age_1D, mass_1D, Ebv_1D, Z_1D
 print 'Solution 1D: ', solution[ii-1,0:4], sigma_left_age, sigma_right_age
 print 'Solution 3D: ', logt_box[index_max_age_3D],logm_box[index_max_age_3D],Ebv_box[index_max_age_3D]
 print 
 del M0,M0_prime,models_selected,logt_box_filtered, logm_box_filtered, Ebv_box_filtered, weights_filtered, d_direct_square


print solution[0:20,:]
np.savetxt("/home/philippe/Desktop/Clusters_Solutions.txt",solution)


