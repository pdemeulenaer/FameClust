#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
#											    !
#											    !
#		FameClust 10.3 and Chi Square methods 		 			    !	
#		(Finding of Age Mass and Extinction of star Clusters)			    !
#		Philippe de Meulenaer, PhD Student in Astrophysics (year four)		    !
#		Astronomical Observatory, Vilnius University				    !
#											    !
#											    !
#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
#
# Marie je te confie cela...
#
# Date of conception: 30 December 2013
# Last update : 30 December 2013
# 
#	   (No pain, no gain!)
#         (Let's DO it!)
#        O 
#    ___o
#   (*,*)
#   (   )
#---"--"----
#
# 
# Execution: 
# time python FameClust_python_V103.py InputFameClustNEW_UBVRI_Z01900_M400 1 10 n00
#
# --------------------------------------
# Declaration of imported python modules
# --------------------------------------

import numpy as np
import numexpr as ne
import scipy
import os
import math
import time
import random
from random import gauss
from pylab import *
import sys
#from numba import *
import Lecture_module  # (Module located in /home/philippe/Desktop/Discrete_models_comparaison_jtao)

# ------------------------
# Declaration of functions
# ------------------------

def dereddening(M1,A_lambda_filters_selected,Rv,Ebv):
 M2 = M1 - A_lambda_filters_selected * Rv*Ebv
 return M2

def reddening(M1,A_lambda_filters_selected,Rv,Ebv):
 M2 = ne.evaluate("M1 + A_lambda_filters_selected * Rv*Ebv")
 return M2

#@autojit #(backend='ast')
def Count_of_models_in_OB(M1,M0,A_lambda_filters_selected):
 	#Loop on the extinction to find all the models in the OB
	for Ext in range(1,102):
	  print Ext
	  Ebv = (Ext-1) * 0.01

	  #We apply extinction on all the models of the grid and build M1_M0_prime
	  #for ff in range(0,number_filters):
	   #M0_prime[:,ff] = M0[:,ff] + A_lambda_filters_selected[ff] * Rv * Ebv
	  # M1_M0_prime[:,ff] = abs(M0[:,ff] + A_lambda_filters_selected[ff] * Rv * Ebv - M1[ff])

	  # Selection of models in the OB
	  #ID_models[:] = 0
	  #for ii in range(1,N_bin_all_nodes):
	  # in_box=0 
	  # for ff in range(0,number_filters):
	  #   if abs(M1_M0_prime[ii,ff])<sigma_factor*sigma_magnitude :	#General case
          #   #if abs(M1_M0[ii,ff])<sigma_factor*sigma_magnitude :	#IF WE DO NOT WANT EXTINCTION!!!!!!!
	  #    in_box=1
	  #   else:
	  #    in_box=0
	  #    break
	return
















# -------------------------
# Loading of the input file
# -------------------------
print
print 80*'-'
print
print 50*'-'
print 'Loading of InputFile'
print 50*'-'
print


InputFile_Name = sys.argv[1] # The name of input file is given during execution of the script
number_begin = int(sys.argv[2])
number_end = int(sys.argv[3])
Z_selected = sys.argv[4]

#Determination of the metallicity in the different needed formats: Z, [M/H] and zz (index)
#age=7.0
#mass=3.0
#age_indice = '700'
#mass_indice = '300'
#Z_indice = Z_selected
#aa, mm, zz = Lecture_module.age_mass_Z_December2011_inverse(age, mass, Z_selected, age_indice, mass_indice, Z_indice)
#age, mass, Z_selected, age_indice, mass_indice, Z_indice_selected = Lecture_module.age_mass_Z_December2011(aa,mm,zz)
#age,mass=0.,0.

Z_indice_selected = Z_selected
Z,zz = Lecture_module.Zindex_to_Z_and_zz(Z_indice_selected)

InputFile = open('/home/philippe/Desktop/Discrete_models_comparaison_jtao/SC_Parameters_20/'+InputFile_Name).readlines()
my_list = []
for line in InputFile:
    item = str.split(line)
    if item[0][0] != '#':
     my_list.append(item[0])

number_filters = int(my_list[0])
print 'Number of filters selected:                 ', number_filters

filters_selected_index = np.arange(number_filters) 	#integer array containing the indexes of the selected filters 
for ii in range(0,number_filters):
 filters_selected_index[ii] = int(my_list[ii+1])
print 'Indexes of filters selected:               ', filters_selected_index

Distance_modulus_host_galaxy = int(my_list[number_filters+1])
print 'Distance modulus of the host galaxy:        ', Distance_modulus_host_galaxy
app_or_abs = int(my_list[number_filters+2])
print 'Apparent mags [1], Absolute mags [2]:       ', app_or_abs
file_observed_clusters = my_list[number_filters+3]
print 'Input file of the observed clusters:        '
print '    ',file_observed_clusters
number_cluster_observed = int(my_list[number_filters+4])
print 'Number of observed clusters:                ',  number_cluster_observed	#[obsolete]
choice_extinction = int(my_list[number_filters+5])
print 'Cluster(s) extincted [1], not extincted [2]:', choice_extinction
choice_extinction_law = int(my_list[number_filters+6])
print 'Extinction law of MW [1], of LMC [2]:       ', choice_extinction_law
path_file_out_cluster = my_list[number_filters+7]
print 'Path of output files for derived parameters:' 
print '    ',path_file_out_cluster
print
print 50*'-'
print 'InputFile loaded'
print 50*'-'
print
#raw_input()



# -----------------------------------------------------------------------------------------
#Loading of the A_lambda (extinction parameters) for the filters selected in the input file
# -----------------------------------------------------------------------------------------
print
print 50*'-'
print 'Loading of the A_lambda (extinction parameters)'
print 50*'-'
print
# lambda, lambda_f_MW, lambda_f_LMC, index of filter [1-->52]
filters_A_lambda = np.genfromtxt('Filters_information.dat',comments='#')
if choice_extinction_law == 1:	#MW
 A_lambda_filters_selected = filters_A_lambda[filters_selected_index-1,1]
 Rv = 3.1
if choice_extinction_law == 2:	#LMC
 A_lambda_filters_selected = filters_A_lambda[filters_selected_index-1,2]
 Rv = 3.4
print A_lambda_filters_selected
print
print 50*'-'
print 'A_lambda loaded'
print 50*'-'
print
del filters_A_lambda
#raw_input()



# -----------------------------------------------------------------------------------------
#Loading of the observations
# -----------------------------------------------------------------------------------------
print
print 50*'-'
print 'Loading of the observation'
print 50*'-'
print
#file: file_observed_clusters
#print path_file_out_cluster+file_observed_clusters
data_input = np.genfromtxt(path_file_out_cluster+file_observed_clusters, comments='#')
M1_input = data_input[:,filters_selected_index+4]
print 'M1: ', M1_input
#print 'M1[0:number_filters]: ', M1[0:number_filters]
del data_input
print 50*'-'
print 'Observation loaded'
print 50*'-'
print
#raw_input()



# ----------------------------------------------
# Loading of the grid of models (from .npy file)
# ----------------------------------------------
print
print 50*'-'
print 'Loading of the grid of models (from .npy file)'
print 50*'-'
print
#Case of 1 metallicity	
#grid = np.load('/home/philippe/Desktop/Discrete_models_comparaison_jtao/Transforming_grid_in_npy_files/Grid_gCMD014_71_81_Z{0}_AllB_HST_20pc_untruncated_iso.npy'.format(Z_indice_selected))
grid = np.load('/home/philippe/Desktop/Discrete_models_comparaison_jtao/Transforming_grid_in_npy_files/Grid_HRS_Z{0}_ExpFactor6_Kroupa.npy'.format(Z_indice_selected))
Age_grid = grid[:,0][np.newaxis].T
Mass_grid = grid[:,1][np.newaxis].T
zero = grid[:,0][np.newaxis].T * 0.
Z_grid = grid[:,0][np.newaxis].T * 0.
Z_grid[:] = Z
print 'The metallicity', Z_grid[0]
N_bin_all_nodes = len(Z_grid)
#print N_bin_all_nodes
print 
print
M0 = grid[:,filters_selected_index+1]
print
print 'M0, the models: ',M0
print
# Age, Mass, Ebv, Z, Magnitudes, d_perp, Proba
Grid_completed = np.concatenate((Age_grid,Mass_grid,zero,Z_grid,M0,zero,zero), axis=1)
print
print Grid_completed
print
print
print 50*'-'
print 'Grid Loaded'
print 50*'-'
print
del grid #We do not need to keep all the grid in memory, just the bands that we loaded in M3 array and Grid_completed!
del Age_grid
del Mass_grid
del zero
del Z_grid








#Preparation of the histogram bins
age_histo, age_edges = np.histogram(Grid_completed[0:10,3], bins=71, range=[6.575,10.125], normed=False, density=None)
age_centers = (age_edges[:-1]+age_edges[1:])/2
mass_histo, mass_edges = np.histogram(Grid_completed[0:10,3], bins=81, range=[1.975,6.025], normed=False, density=None)
mass_centers = (mass_edges[:-1]+mass_edges[1:])/2
Ebv_histo, Ebv_edges = np.histogram(Grid_completed[0:10,3], bins=101, range=[-0.01,2.01], normed=False, density=None)
Ebv_centers = (Ebv_edges[:-1]+Ebv_edges[1:])/2
Ebv_centers[0]=0.
Z_histo, Z_edges = np.histogram(Grid_completed[0:10,3], bins=13, range=[-2.3,0.3], normed=False, density=None)
Z_centers = (Z_edges[:-1]+Z_edges[1:])/2


#raw_input()



solution = np.zeros((10000,4))
sigma_magnitude = 0.05
#sigma_magnitude = 0.15


#Multiprocessing should start HERE. All what is after should be put in a function that processors would call independently

#Here will start the loop on the 10000 observed clusters!
for list_cluster in range(0,20): #number_cluster_observed):
	print 'Cluster ', list_cluster+1

 
	# ------------------------------------------------------------------------
	# Reddening of the observation, to obtain the line going through M1 and M2
	# ------------------------------------------------------------------------
	#We first take the observation from the list of observed clusters:
	M1 = M1_input[list_cluster]
	#print 'M1, the observation: ', M1
	#We then deredden the observation by a quantity E(B-V)=2, to have the line (M2,M1)
	M2 = dereddening(M1,A_lambda_filters_selected,Rv,2)
	#print 'M2, (M1 dereddened of E(B-V)=2): ',M2



	# ----------------------------------------------------------
	# Derivation of the distances d_perpendicular and d_parallel
	# ----------------------------------------------------------
	M1_M0 = ne.evaluate("M1-M0")
	M2_M1 = ne.evaluate("M2-M1")
	d_direct_square = ne.evaluate("M1_M0*M1_M0").sum(axis=1)
 	M2_M1_square = ne.evaluate("M2_M1*M2_M1").sum()
 	M2_M1_square_inverse = ne.evaluate("M2_M1_square**-1")
	d_parallel_square = ne.evaluate("M1_M0*M2_M1").sum(axis=1)
	d_parallel_square = ne.evaluate("d_parallel_square * d_parallel_square * M2_M1_square_inverse")
	d_perpendicular_square = ne.evaluate("d_direct_square - d_parallel_square")
	d_perpendicular = ne.evaluate("d_perpendicular_square**0.5")
	#d_parallel = ne.evaluate("d_parallel_square**0.5")
	#d_direct = ne.evaluate("d_direct_square**0.5")
	#print 'd_perpendicular: ', d_perpendicular_square**0.5
	#print 'd_parallel: ',      d_parallel_square**0.5
	#print 'd_direct: ',        d_direct_square**0.5
	Grid_completed[:,3+number_filters+1] = d_perpendicular[:]

	Ebv_vector = ne.evaluate("2*(d_parallel_square*M2_M1_square_inverse)**0.5")
	Grid_completed[:,2] = Ebv_vector[:]
	#Grid_completed[:,3+number_filters+2] = d_perpendicular_square[:]**(-1)  #Probability 1/d_perp**2
	Grid_completed[:,3+number_filters+2] = np.exp(-0.5*(d_perpendicular_square[:]/sigma_magnitude)**2)  #Probability gaussian
	print



	# -----------------------------
	# Selection of models in the OB
	# -----------------------------
	selection = ne.evaluate('(d_perpendicular < 3*sigma_magnitude) & (Ebv_vector <=1)')  #And to restrict extinction too, i should also adopt a constrain on Ebv_vector or d_parallel!!! 
	#selection = ne.evaluate("d_perpendicular < 6*sigma_magnitude")
	Grid_completed_selection = Grid_completed[selection,:]

	#If we want to save the models OB for each observed cluster (big data)
	#np.save("/home/philippe/Desktop/Clusters_{0}.npy".format(list_cluster),Grid_completed_selection)
	#np.savetxt("/home/philippe/Desktop/Clusters_{0}.txt".format(list_cluster),Grid_completed_selection)



	# ------------------------------------
	# Building the probabilitieS 1D		#I could also build the 3D!!!
	# ------------------------------------
	
	age_histo, age_edges = np.histogram(Grid_completed_selection[:,0], bins=71, range=[6.575,10.125], normed=False, weights=Grid_completed_selection[:,3+number_filters+2], density=None)
	index_max_age = np.argmax(age_histo)
	#age_max = age_edges[index_max_age] 	#This is an approximation to be corrected!
	age_max = age_centers[index_max_age] 	#This is an approximation to be corrected!


	mass_histo, mass_edges = np.histogram(Grid_completed_selection[:,1], bins=81, range=[1.975,6.025], normed=False, weights=Grid_completed_selection[:,3+number_filters+2], density=None)
	index_max_mass = np.argmax(mass_histo)
	#mass_max = mass_edges[index_max_mass] 	#This is an approximation to be corrected!
	mass_max = mass_centers[index_max_mass] 	#This is an approximation to be corrected!

	Ebv_histo, Ebv_edges = np.histogram(Grid_completed_selection[:,2], bins=101, range=[-0.01,2.01], normed=False, weights=Grid_completed_selection[:,3+number_filters+2], density=None)
	index_max_Ebv = np.argmax(Ebv_histo)
	#Ebv_max = Ebv_edges[index_max_Ebv] 	#This is an approximation to be corrected!
	Ebv_max = Ebv_centers[index_max_Ebv] 	#This is an approximation to be corrected!

	Z_histo, Z_edges = np.histogram(Grid_completed_selection[:,3], bins=13, range=[-2.3,0.3], normed=False, weights=Grid_completed_selection[:,3+number_filters+2], density=None)
	index_max_Z = np.argmax(Z_histo)
	#Z_max = Z_edges[index_max_Z] 	#This is an approximation to be corrected!
	Z_max = Z_centers[index_max_Z] 	#This is an approximation to be corrected!


	solution[list_cluster,0:4] = age_max, mass_max, Ebv_max, Z_max



print solution[0:20,:]
np.savetxt("/home/philippe/Desktop/Clusters_Solutions.txt",solution)
np.savetxt(path_file_out_cluster+"Clusters_Solutions.txt",solution)
print 'Done!'
os.system("date")
print 80*'-'

# -------------------------- 
# Deallocation of the memory
# -------------------------- 
#del grid  
del M0,M1,M2
del M1_M0,M2_M1,M2_M1_square_inverse
del d_direct_square,d_perpendicular, Ebv_vector
del d_perpendicular_square,d_parallel_square  
del Grid_completed
del solution


















'''
solution = np.zeros((number_cluster_observed,8))
sigma_magnitude = 0.05
#sigma_magnitude = 0.15

counting = np.zeros(number_cluster_observed)
OB_size  = np.zeros(number_cluster_observed)
ID_models= np.zeros(N_bin_all_nodes)
Grid_completed_selection = np.zeros(20000000)
M1_M0_prime = np.zeros((N_bin_all_nodes,number_filters))


for list_cluster in range(number_begin-1,number_end):

	print 'Cluster ', list_cluster+1
	counting[list_cluster] = 0
	OB_size[list_cluster] = 3
	sigma_factor = 3	#Indicates the size of the OB, in sigma units
 
	# ------------------------------------------------------------------------
	# Reddening of the observation, to obtain the line going through M1 and M2
	# ------------------------------------------------------------------------
	#We first take the observation from the list of observed clusters:
	M1 = M1_input[list_cluster]
	print 'M1, the observation: ', M1


	Count_of_models_in_OB(M1,M0,A_lambda_filters_selected)


 	#Loop on the extinction to find all the models in the OB
	for Ext in range(1,102):
	  Ebv = (Ext-1) * 0.01

	  #We apply extinction on all the models of the grid and build M1_M0_prime
	  for ff in range(0,number_filters):
	   #M0_prime[:,ff] = M0[:,ff] + A_lambda_filters_selected[ff] * Rv * Ebv
	   M1_M0_prime[:,ff] = abs(M0[:,ff] + A_lambda_filters_selected[ff] * Rv * Ebv - M1[ff])

	  # Selection of models in the OB
	  #ID_models[:] = 0
	  for ii in range(1,N_bin_all_nodes):
	   in_box=0 
	   for ff in range(0,number_filters):
	     if abs(M1_M0_prime[ii,ff])<sigma_factor*sigma_magnitude :	#General case
             #if abs(M1_M0[ii,ff])<sigma_factor*sigma_magnitude :	#IF WE DO NOT WANT EXTINCTION!!!!!!!
	      in_box=1
	     else:
	      in_box=0
	      break



	   #if in_box==1:
	   #   counting[list_cluster] = counting[list_cluster] + 1
	   #   #ID_models(counting(list)) = ii
	   #   Grid_completed_selection[counting[list_cluster],:] = Grid_completed[ii,:]
	   #   Grid_completed_selection[counting[list_cluster],3] = Ebv 
	   #   #Grid_completed_selection(counting[list_cluster],4+number_filters+2+1:4+number_filters+2+number_filters) =  M1_M0_prime[ii,1:number_filters]




'''










'''

#Multiprocessing should start HERE. All what is after should be put in a function that processors would call independently
#Here will start the loop on the 10000 observed clusters!
#for list_cluster in range(0,20): #number_cluster_observed):
for list_cluster in range(number_begin,number_end): #number_cluster_observed):
	print 'Cluster ', list_cluster+1

 
	# ------------------------------------------------------------------------
	# Reddening of the observation, to obtain the line going through M1 and M2
	# ------------------------------------------------------------------------
	#We first take the observation from the list of observed clusters:
	M1 = M1_input[list_cluster]
	#print 'M1, the observation: ', M1
	#We then deredden the observation by a quantity E(B-V)=2, to have the line (M2,M1)
	M2 = dereddening(M1,A_lambda_filters_selected,Rv,2)
	#print 'M2, (M1 dereddened of E(B-V)=2): ',M2



	# ----------------------------------------------------------
	# Derivation of the distances d_perpendicular and d_parallel
	# ----------------------------------------------------------
	M1_M0 = ne.evaluate("M1-M0")
	M2_M1 = ne.evaluate("M2-M1")
	d_direct_square = ne.evaluate("M1_M0*M1_M0").sum(axis=1)
 	M2_M1_square = ne.evaluate("M2_M1*M2_M1").sum()
 	M2_M1_square_inverse = ne.evaluate("M2_M1_square**-1")
	d_parallel_square = ne.evaluate("M1_M0*M2_M1").sum(axis=1)
	d_parallel_square = ne.evaluate("d_parallel_square * d_parallel_square * M2_M1_square_inverse")
	d_perpendicular_square = ne.evaluate("d_direct_square - d_parallel_square")
	d_perpendicular = ne.evaluate("d_perpendicular_square**0.5")
	#d_parallel = ne.evaluate("d_parallel_square**0.5")
	#d_direct = ne.evaluate("d_direct_square**0.5")
	#print 'd_perpendicular: ', d_perpendicular_square**0.5
	#print 'd_parallel: ',      d_parallel_square**0.5
	#print 'd_direct: ',        d_direct_square**0.5
	Grid_completed[:,3+number_filters+1] = d_perpendicular[:]

	Ebv_vector = ne.evaluate("2*(d_parallel_square*M2_M1_square_inverse)**0.5")
	Grid_completed[:,2] = Ebv_vector[:]
	Grid_completed[:,3+number_filters+2] = d_perpendicular_square[:]**(-1)  #Probability 1/d_perp**2




	# -----------------------------
	# Selection of models in the OB
	# -----------------------------
	#Traditional OB
	#selection = ne.evaluate("d_perpendicular < 3*sigma_magnitude")
	#Enlarged OB
	#selection = ne.evaluate("d_perpendicular < 6*sigma_magnitude")

	#Variable OB  (Tool to take model further when OB not enough populated...)
	selection = ne.evaluate("d_perpendicular < sigma_magnitude")
        flag = 1
	if len(d_perpendicular[selection]) <1000:
	 selection = ne.evaluate("d_perpendicular < 2*sigma_magnitude")
         flag = 2
	 if len(d_perpendicular[selection]) <1000: 
	  selection = ne.evaluate("d_perpendicular < 3*sigma_magnitude")
	  flag = 3
	  if len(d_perpendicular[selection]) <1000: 
	   selection = ne.evaluate("d_perpendicular < 4*sigma_magnitude")
           flag = 4
	   if len(d_perpendicular[selection]) <1000: 
	    selection = ne.evaluate("d_perpendicular < 5*sigma_magnitude")
	    flag = 5
	    if len(d_perpendicular[selection]) <1000: 
	     selection = ne.evaluate("d_perpendicular < 6*sigma_magnitude")
	     flag = 6

	print ' #OB = ', len(d_perpendicular[selection]), '; OB = ',  flag, ' sigmas'
	print
	Grid_completed_selection = Grid_completed[selection,:]

	#If we want to save the models OB for each observed cluster (big data)
	#np.save(path_file_out_cluster+"Clusters_OB_{0}_Z{1}.npy".format(list_cluster+1,Z_indice_selected),Grid_completed_selection,fmt='%7.3f')
	#np.savetxt(path_file_out_cluster+"Clusters_OB_{0}_Z{1}.dat".format(list_cluster+1,Z_indice_selected),Grid_completed_selection,fmt='%7.3f')



	# ------------------------------------
	# Building the probabilitieS 1D
	# ------------------------------------
	
	age_histo, age_edges = np.histogram(Grid_completed_selection[:,0], bins=71, range=[6.575,10.125], normed=False, weights=Grid_completed_selection[:,3+number_filters+2], density=None)
	index_max_age = np.argmax(age_histo)
	age_max = age_centers[index_max_age]
	age_max_height = age_histo[index_max_age]

	mass_histo, mass_edges = np.histogram(Grid_completed_selection[:,1], bins=81, range=[1.975,6.025], normed=False, weights=Grid_completed_selection[:,3+number_filters+2], density=None)
	index_max_mass = np.argmax(mass_histo)
	mass_max = mass_centers[index_max_mass] 
	mass_max_height = mass_histo[index_max_mass]	

	Ebv_histo, Ebv_edges = np.histogram(Grid_completed_selection[:,2], bins=101, range=[-0.01,2.01], normed=False, weights=Grid_completed_selection[:,3+number_filters+2], density=None)
	index_max_Ebv = np.argmax(Ebv_histo)
	Ebv_max = Ebv_centers[index_max_Ebv] 	
	Ebv_max_height = Ebv_histo[index_max_Ebv]

	Z_histo, Z_edges = np.histogram(Grid_completed_selection[:,3], bins=13, range=[-2.3,0.3], normed=False, weights=Grid_completed_selection[:,3+number_filters+2], density=None)
	index_max_Z = np.argmax(Z_histo)
	Z_max = Z_centers[index_max_Z] 
	Z_max_height = Z_histo[index_max_Z]


	solution[list_cluster,0:8] = age_max, mass_max, Ebv_max, Z_max, age_max_height, mass_max_height, Ebv_max_height, Z_max_height



print solution[0:20,:]
np.savetxt("/home/philippe/Desktop/Clusters_Solutions_Z{0}.txt".format(Z_indice_selected),solution,fmt='%10.2f')
np.savetxt(path_file_out_cluster+"Clusters_Solutions_Z{0}.txt".format(Z_indice_selected),solution,fmt='%10.2f')
print 'Done!'
os.system("date")
print 80*'-'

# -------------------------- 
# Deallocation of the memory
# -------------------------- 
#del grid  
del M0,M1,M2
del M1_M0,M2_M1,M2_M1_square_inverse
del d_direct_square,d_perpendicular, Ebv_vector
del d_perpendicular_square,d_parallel_square  
del Grid_completed
del solution


'''


#Preparation of the histogram bins
#age_histo, age_edges = np.histogram(Grid_completed[0:10,3], bins=71, range=[6.575,10.125], normed=False, density=None)
#age_centers = (age_edges[:-1]+age_edges[1:])/2
#mass_histo, mass_edges = np.histogram(Grid_completed[0:10,3], bins=81, range=[1.975,6.025], normed=False, density=None)
#mass_centers = (mass_edges[:-1]+mass_edges[1:])/2
#Ebv_histo, Ebv_edges = np.histogram(Grid_completed[0:10,3], bins=101, range=[-0.01,2.01], normed=False, density=None)
#Ebv_centers = (Ebv_edges[:-1]+Ebv_edges[1:])/2
#Ebv_centers[0]=0.
#Z_histo, Z_edges = np.histogram(Grid_completed[0:10,3], bins=13, range=[-2.3,0.3], normed=False, density=None)
#Z_centers = (Z_edges[:-1]+Z_edges[1:])/2


